
import requests
from bs4 import BeautifulSoup #python library that is used for web scraping purposes to pull the data out of HTML and XML
import pandas as pd  
import streamlit as st #open source app framework in python

st.set_page_config(page_title="ok")
st.header("Webscraping project")  #heading of the project
st.subheader("LET'S SEARCH SOME JOBS...") #subheading

def extract(page):  #extract from indeed page
    headers={'User-Agnet' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36'} #which broser using
    url=f'https://in.indeed.com/jobs?q=python%20developer&l=Pune,%20Maharashtra&start={page}&vjk=674f20bad0f2174e'
    r=requests.get(url,headers) #storing html code to r
    soup = BeautifulSoup(r.content,'html.parser') #parsing html code to soup
    return soup

def transform(soup): #
    divs = soup.find_all('div',class_ = 'job_seen_beacon') 
    for item in divs:
        title = item.find('span').text.strip() #strip used to remove left and right spaces
        company = item.find('span',class_='companyName').text.strip()
        try:
            salary = item.find('div',class_='metadata salary-snippet-container').text.strip()
        except:
            salary = '' 
        summary = item.find('div',class_='job-snippet').text.strip().replace('\n','')
        
        
        job = {   #we have 4 field in our page
            'title' : title,
            'company' : company,
            'salary' : salary,
            'summary' : summary
        }
        
        joblist.append(job) #add to the list
    return


joblist = []

for i in range(0,40,10):
    print(f'getting page,{i}')
    c = extract(0)
    transform(c)
    
print(len(joblist))

df = pd.DataFrame(joblist)

st.dataframe(df)

print(df.head())
df.to_csv('jobs.csv')
